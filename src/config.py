OLLAMA_URL = "http://localhost:11434"
MODELS = {
    "info_check": "llama3.2:3b",
    "creative": "llama3.2:3b",
    "describe": "llama3.2:3b",
    "narration": "gemma3:12b",
    "summarise": "llama3.2:3b",
    "data": "phi3.5:3.8b ",
    "time_estimator" : "llama3.2:3b",
    "success_estimator" : "llama3.2:3b"
}
TEMPERATURES = {
    "auditor": 0.2,
    "story": 1,
    "memory": 0.3
}
META = {
    "tone" : "dark, grimy, shakespearean"
}